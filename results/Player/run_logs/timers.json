{
    "name": "root",
    "gauges": {
        "Player.Policy.Entropy.mean": {
            "value": 6.565335273742676,
            "min": 1.8331336975097656,
            "max": 6.565335273742676,
            "count": 7
        },
        "Player.Policy.Entropy.sum": {
            "value": 65653.3515625,
            "min": 18624.638671875,
            "max": 65653.3515625,
            "count": 7
        },
        "Player.Environment.EpisodeLength.mean": {
            "value": 44.57077625570776,
            "min": 29.28048780487805,
            "max": 47.69607843137255,
            "count": 7
        },
        "Player.Environment.EpisodeLength.sum": {
            "value": 9761.0,
            "min": 9604.0,
            "max": 9877.0,
            "count": 7
        },
        "Player.Step.mean": {
            "value": 69968.0,
            "min": 9996.0,
            "max": 69968.0,
            "count": 7
        },
        "Player.Step.sum": {
            "value": 69968.0,
            "min": 9996.0,
            "max": 69968.0,
            "count": 7
        },
        "Player.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.2894412875175476,
            "min": -0.6268174648284912,
            "max": -0.13758862018585205,
            "count": 7
        },
        "Player.Policy.ExtrinsicValueEstimate.sum": {
            "value": -82.20132446289062,
            "min": -226.9079132080078,
            "max": -40.17587661743164,
            "count": 7
        },
        "Player.Environment.CumulativeReward.mean": {
            "value": -0.38264840133658284,
            "min": -0.7765243955683417,
            "max": -0.22352941553382313,
            "count": 7
        },
        "Player.Environment.CumulativeReward.sum": {
            "value": -83.79999989271164,
            "min": -254.7000017464161,
            "max": -45.60000076889992,
            "count": 7
        },
        "Player.Policy.ExtrinsicReward.mean": {
            "value": -0.38264840133658284,
            "min": -0.7765243955683417,
            "max": -0.22352941553382313,
            "count": 7
        },
        "Player.Policy.ExtrinsicReward.sum": {
            "value": -83.79999989271164,
            "min": -254.7000017464161,
            "max": -45.60000076889992,
            "count": 7
        },
        "Player.Losses.PolicyLoss.mean": {
            "value": 0.2429332037741974,
            "min": 0.24085755545633314,
            "max": 0.25086434045485523,
            "count": 7
        },
        "Player.Losses.PolicyLoss.sum": {
            "value": 18.948789894387396,
            "min": 18.282897763801703,
            "max": 20.727527301612113,
            "count": 7
        },
        "Player.Losses.ValueLoss.mean": {
            "value": 0.22944164126703945,
            "min": 0.09326746149069075,
            "max": 0.23144148163701242,
            "count": 7
        },
        "Player.Losses.ValueLoss.sum": {
            "value": 17.896448018829076,
            "min": 7.927734226708714,
            "max": 17.896448018829076,
            "count": 7
        },
        "Player.Policy.LearningRate.mean": {
            "value": 0.00026099581300139996,
            "min": 0.00026099581300139996,
            "max": 0.00029706798450675057,
            "count": 7
        },
        "Player.Policy.LearningRate.sum": {
            "value": 0.020357673414109195,
            "min": 0.020357673414109195,
            "max": 0.025250778683073797,
            "count": 7
        },
        "Player.Policy.Epsilon.mean": {
            "value": 0.1869986,
            "min": 0.1869986,
            "max": 0.19902266117647058,
            "count": 7
        },
        "Player.Policy.Epsilon.sum": {
            "value": 14.5858908,
            "min": 14.516304,
            "max": 16.9169262,
            "count": 7
        },
        "Player.Policy.Beta.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 7
        },
        "Player.Policy.Beta.sum": {
            "value": 78.0,
            "min": 75.0,
            "max": 85.0,
            "count": 7
        },
        "Player.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 7
        },
        "Player.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 7
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1650894511",
        "python_version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\sieme\\anaconda3\\envs\\unity_rl\\Scripts\\mlagents-learn config/Player.yaml --run-id=Player --force",
        "mlagents_version": "0.28.0",
        "mlagents_envs_version": "0.28.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.11.0",
        "numpy_version": "1.21.5",
        "end_time_seconds": "1650894976"
    },
    "total": 465.04655790000004,
    "count": 1,
    "self": 0.007961700000066685,
    "children": {
        "run_training.setup": {
            "total": 0.10802330000000016,
            "count": 1,
            "self": 0.10802330000000016
        },
        "TrainerController.start_learning": {
            "total": 464.93057289999996,
            "count": 1,
            "self": 0.3548886999975025,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.3106656,
                    "count": 1,
                    "self": 6.3106656
                },
                "TrainerController.advance": {
                    "total": 458.1333368000025,
                    "count": 16518,
                    "self": 0.3483808000015074,
                    "children": {
                        "env_step": {
                            "total": 156.92376789999884,
                            "count": 16518,
                            "self": 101.75627759999959,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 54.94537759999939,
                                    "count": 16518,
                                    "self": 0.9410882000011611,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 54.00428939999823,
                                            "count": 15069,
                                            "self": 14.893527099999247,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 39.11076229999898,
                                                    "count": 15069,
                                                    "self": 39.11076229999898
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.22211269999985284,
                                    "count": 16518,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 458.9673895999997,
                                            "count": 16518,
                                            "is_parallel": true,
                                            "self": 374.90999109999996,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0005058000000000007,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0002418000000004028,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0002639999999995979,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.0002639999999995979
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 84.05689269999974,
                                                    "count": 16518,
                                                    "is_parallel": true,
                                                    "self": 1.7776159000055571,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 1.9199162999970243,
                                                            "count": 16518,
                                                            "is_parallel": true,
                                                            "self": 1.9199162999970243
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 73.96659749999961,
                                                            "count": 16518,
                                                            "is_parallel": true,
                                                            "self": 73.96659749999961
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 6.39276299999754,
                                                            "count": 16518,
                                                            "is_parallel": true,
                                                            "self": 3.3992093999961313,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 2.993553600001409,
                                                                    "count": 66072,
                                                                    "is_parallel": true,
                                                                    "self": 2.993553600001409
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 300.86118810000215,
                            "count": 16518,
                            "self": 0.4695931000056248,
                            "children": {
                                "process_trajectory": {
                                    "total": 8.896697099996867,
                                    "count": 16518,
                                    "self": 8.74189909999684,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.15479800000002797,
                                            "count": 1,
                                            "self": 0.15479800000002797
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 291.49489789999967,
                                    "count": 591,
                                    "self": 14.135612300001185,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 277.3592855999985,
                                            "count": 21801,
                                            "self": 277.3592855999985
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.0999999631167157e-06,
                    "count": 1,
                    "self": 1.0999999631167157e-06
                },
                "TrainerController._save_models": {
                    "total": 0.13168070000000398,
                    "count": 1,
                    "self": 0.0020742000000382177,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.12960649999996576,
                            "count": 1,
                            "self": 0.12960649999996576
                        }
                    }
                }
            }
        }
    }
}